2025-09-27 23:54:55,099 - __main__ - INFO - === API Starting - Logging Config Applied ===
2025-09-27 23:54:55,273 - app - INFO - === API Starting - Logging Config Applied ===
2025-09-27 23:54:55,285 - app - INFO - 🚀 API Startup
2025-09-27 23:54:55,293 - app - INFO - ✅ SentencePiece tokenizer loaded from model/multi_tokenizer.model
2025-09-27 23:54:56,486 - app - INFO - 🔧 Using 4-bit quantization for faster inference
2025-09-27 23:54:58,052 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-27 23:55:12,835 - app - INFO - ✅ Model loaded with 4-bit quantization
2025-09-27 23:55:12,836 - app - INFO - ✅ Model loaded: AhinsaAI/ahinsa0.5-llama3.2-3B
2025-09-27 23:55:34,044 - kb_integration - INFO - No KB endpoint configured, using enhanced mock response
2025-09-27 23:57:16,026 - kb_integration - INFO - No KB endpoint configured, using enhanced mock response
2025-09-27 23:57:42,220 - kb_integration - INFO - No KB endpoint configured, using enhanced mock response
2025-09-27 23:57:49,288 - kb_integration - INFO - No KB endpoint configured, using enhanced mock response
2025-09-27 23:58:10,334 - kb_integration - INFO - No KB endpoint configured, using enhanced mock response
2025-09-27 23:58:59,006 - kb_integration - INFO - No KB endpoint configured, using enhanced mock response
2025-09-28 00:00:14,751 - app - INFO - 🔌 API Shutdown
2025-09-28 00:00:26,464 - __main__ - INFO - === API Starting - Logging Config Applied ===
2025-09-28 00:00:26,657 - app - INFO - === API Starting - Logging Config Applied ===
2025-09-28 00:00:26,670 - app - INFO - 🚀 API Startup
2025-09-28 00:00:26,679 - app - INFO - ✅ SentencePiece tokenizer loaded from model/multi_tokenizer.model
2025-09-28 00:00:27,978 - app - INFO - 🔧 Using 4-bit quantization for faster inference
2025-09-28 00:00:29,626 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-28 00:00:51,659 - app - INFO - ✅ Model loaded with 4-bit quantization
2025-09-28 00:00:51,660 - app - INFO - ✅ Model loaded: AhinsaAI/ahinsa0.5-llama3.2-3B
2025-09-28 00:01:32,849 - kb_integration - INFO - No KB endpoint configured, using enhanced mock response
2025-09-28 00:01:41,090 - kb_integration - INFO - No KB endpoint configured, using enhanced mock response
2025-09-28 00:01:47,262 - kb_integration - INFO - No KB endpoint configured, using enhanced mock response
2025-09-28 00:41:35,909 - kb_integration - INFO - No KB endpoint configured, using enhanced mock response
2025-09-28 01:31:06,604 - kb_integration - INFO - No KB endpoint configured, using enhanced mock response
2025-09-28 01:32:15,727 - app - INFO - 🔌 API Shutdown
2025-09-28 01:32:35,416 - __main__ - INFO - === API Starting - Logging Config Applied ===
2025-09-28 01:32:35,612 - app - INFO - === API Starting - Logging Config Applied ===
2025-09-28 01:32:35,622 - app - INFO - 🚀 API Startup
2025-09-28 01:32:35,628 - app - INFO - ✅ SentencePiece tokenizer loaded from model/multi_tokenizer.model
2025-09-28 01:32:36,909 - app - INFO - 🔧 Using 4-bit quantization for faster inference
2025-09-28 01:32:38,530 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-28 01:32:52,726 - app - INFO - ✅ Model loaded with 4-bit quantization
2025-09-28 01:32:52,726 - app - INFO - ✅ Model loaded: AhinsaAI/ahinsa0.5-llama3.2-3B
2025-09-28 01:33:47,227 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 01:34:00,997 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 01:34:19,782 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 01:34:38,741 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 01:34:59,313 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 01:35:16,300 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 01:35:38,411 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 01:36:01,421 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 01:36:01,528 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 01:36:01,638 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 01:36:01,746 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 01:36:11,106 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 01:36:11,209 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 01:36:11,332 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 01:36:11,428 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 02:15:12,448 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 02:15:23,316 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 02:15:53,558 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 02:17:23,378 - app - INFO - === API Starting - Logging Config Applied ===
2025-09-28 02:17:23,649 - app - INFO - 🚀 API Startup
2025-09-28 02:17:23,661 - app - INFO - ✅ SentencePiece tokenizer loaded from model/multi_tokenizer.model
2025-09-28 02:17:25,076 - app - INFO - 🔧 Using 4-bit quantization for faster inference
2025-09-28 02:17:26,711 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-28 02:17:57,508 - app - INFO - === API Starting - Logging Config Applied ===
2025-09-28 02:17:57,683 - app - INFO - 🚀 API Startup
2025-09-28 02:17:57,691 - app - INFO - ✅ SentencePiece tokenizer loaded from model/multi_tokenizer.model
2025-09-28 02:17:59,069 - app - INFO - 🔧 Using 4-bit quantization for faster inference
2025-09-28 02:18:00,913 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-28 02:18:20,969 - app - INFO - ✅ Model loaded with 4-bit quantization
2025-09-28 02:18:20,970 - app - INFO - ✅ Model loaded: AhinsaAI/ahinsa0.5-llama3.2-3B
2025-09-28 02:18:24,528 - app - INFO - === API Starting - Logging Config Applied ===
2025-09-28 02:18:24,716 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 02:18:24,822 - app - INFO - Generation skipped - generate_response: True, model: False, tokenizer: False
2025-09-28 02:18:44,570 - app - INFO - === API Starting - Logging Config Applied ===
2025-09-28 02:18:44,729 - app - INFO - ✅ SentencePiece tokenizer loaded from model/multi_tokenizer.model
2025-09-28 02:18:46,152 - app - INFO - 🔧 Using 4-bit quantization for faster inference
2025-09-28 02:18:47,853 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-28 02:19:06,882 - app - INFO - ✅ Model loaded with 4-bit quantization
2025-09-28 02:19:06,883 - app - INFO - ✅ Model loaded: AhinsaAI/ahinsa0.5-llama3.2-3B
2025-09-28 02:19:06,895 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 02:20:23,806 - __main__ - INFO - === API Starting - Logging Config Applied ===
2025-09-28 02:20:24,045 - app - INFO - === API Starting - Logging Config Applied ===
2025-09-28 02:20:24,054 - app - INFO - 🚀 API Startup
2025-09-28 02:20:24,062 - app - INFO - ✅ SentencePiece tokenizer loaded from model/multi_tokenizer.model
2025-09-28 02:20:25,340 - app - INFO - 🔧 Using 4-bit quantization for faster inference
2025-09-28 02:20:26,982 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-28 02:20:41,647 - app - INFO - ✅ Model loaded with 4-bit quantization
2025-09-28 02:20:41,648 - app - INFO - ✅ Model loaded: AhinsaAI/ahinsa0.5-llama3.2-3B
2025-09-28 02:21:21,186 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 02:21:21,291 - app - INFO - Starting response generation for query: Can you tell me about GenAI?...
2025-09-28 02:21:21,292 - app - INFO - Generated prompt: Question: Can you tell me about GenAI?
Knowledge Base Answer: I understand you're asking about 'Can ...
2025-09-28 02:21:21,294 - app - INFO - Starting model generation with max_new_tokens: 256
2025-09-28 02:21:42,905 - app - INFO - Full model response: Question: Can you tell me about GenAI?
Knowledge Base Answer: I understand you're asking about 'Can you tell me about GenAI?'. While I'm designed as a multilingual tokenization and language model syst...
2025-09-28 02:21:42,905 - app - INFO - Extracted generated response: I can provide some general information about GenAI, which refers to Artificial General Intelligence ...
2025-09-28 02:22:12,517 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 02:22:12,609 - app - INFO - Starting response generation for query: योग क्या है?...
2025-09-28 02:22:12,609 - app - INFO - Generated prompt: प्रश्न: योग क्या है?
ज्ञान आधार का उत्तर: आपके प्रश्न 'योग क्या है?' के बारे में, मैं यह कह सकता हूं...
2025-09-28 02:22:12,612 - app - INFO - Starting model generation with max_new_tokens: 256
2025-09-28 02:22:35,074 - app - INFO - Full model response: प्रश्न: योग क्या है?
ज्ञान आधार का उत्तर: आपके प्रश्न 'योग क्या है?' के बारे में, मैं यह कह सकता हूं कि यह एक बहुभाषी टोकनाइज़ेशन और भाषा मॉडल प्रणाली का हिस्सा है। अधिक विशिष्ट जानकारी के लिए कृपया अ...
2025-09-28 02:22:35,076 - app - INFO - Extracted generated response: "योग" एक ऐसा शब्द है जिसका अर्थ है "योग" के लिए एक व्यापक शब्द। योग एक प्राचीन भारतीय दर्शन, व्यायाम...
2025-09-28 02:23:00,966 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 02:23:01,076 - app - INFO - Starting response generation for query: भारताची राजधानी काय आहे?...
2025-09-28 02:23:01,076 - app - INFO - Generated prompt: प्रश्न: भारताची राजधानी काय आहे?
ज्ञान आधाराचे उत्तर: हा एक भूगोलाचा प्रश्न आहे। मी तुम्हाला सांगू श...
2025-09-28 02:23:01,078 - app - INFO - Starting model generation with max_new_tokens: 256
2025-09-28 02:23:23,028 - app - INFO - Full model response: प्रश्न: भारताची राजधानी काय आहे?
ज्ञान आधाराचे उत्तर: हा एक भूगोलाचा प्रश्न आहे। मी तुम्हाला सांगू शकतो की भारताची राजधानी नवी दिल्ली आहे। तथापि, ही एक मॉक प्रतिक्रिया आहे - अचूक माहितीसाठी विश्वसनीय ...
2025-09-28 02:23:23,029 - app - INFO - Extracted generated response: भारताची राजधानी म्हणजे ती देशाची प्रशासकीय केंद्रित राजधानी असलेली शहर. भारताची राजधानी नवी दिल्ली आ...
2025-09-28 02:23:37,201 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 02:23:37,310 - app - INFO - Starting response generation for query: What is tokenization?...
2025-09-28 02:23:37,311 - app - INFO - Generated prompt: Question: What is tokenization?
Knowledge Base Answer: I understand you're asking about 'What is tok...
2025-09-28 02:23:37,312 - app - INFO - Starting model generation with max_new_tokens: 256
2025-09-28 02:23:59,789 - app - INFO - Full model response: Question: What is tokenization?
Knowledge Base Answer: I understand you're asking about 'What is tokenization?'. While I'm designed as a multilingual tokenization and language model system, I can prov...
2025-09-28 02:23:59,790 - app - INFO - Extracted generated response: u-n-b-r-e-a-k-a-b-l-e. This allows the model to better understand the individual components of the w...
2025-09-28 02:24:18,185 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 02:24:18,293 - app - INFO - Starting response generation for query: Can you tell me about GenAI?...
2025-09-28 02:24:18,293 - app - INFO - Generated prompt: Question: Can you tell me about GenAI?
Knowledge Base Answer: I understand you're asking about 'Can ...
2025-09-28 02:24:18,296 - app - INFO - Starting model generation with max_new_tokens: 256
2025-09-28 02:24:30,447 - app - INFO - Full model response: Question: Can you tell me about GenAI?
Knowledge Base Answer: I understand you're asking about 'Can you tell me about GenAI?'. While I'm designed as a multilingual tokenization and language model syst...
2025-09-28 02:24:30,448 - app - INFO - Extracted generated response: The provided 'Improved Answer' is based on the knowledge of the AI and Machine Learning Knowledge Ba...
2025-09-28 02:24:46,316 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 02:24:46,422 - app - INFO - Starting response generation for query: Explain the concept of machine learning...
2025-09-28 02:24:46,422 - app - INFO - Generated prompt: Question: Explain the concept of machine learning
Knowledge Base Answer: Hello! I'm here to help you...
2025-09-28 02:24:46,423 - app - INFO - Starting model generation with max_new_tokens: 256
2025-09-28 02:25:07,725 - app - INFO - Full model response: Question: Explain the concept of machine learning
Knowledge Base Answer: Hello! I'm here to help you with your questions. I can communicate in Hindi, Sanskrit, Marathi, and English.

(Source: Multilin...
2025-09-28 02:25:07,726 - app - INFO - Extracted generated response: हेलो! मैं आपके प्रश्नों के लिए यहाँ हूँ। मैं ह...
2025-09-28 02:26:27,190 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 02:26:27,294 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 02:26:27,401 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 02:26:27,510 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 02:27:06,738 - app - INFO - 🔌 API Shutdown
2025-09-28 02:30:37,378 - app - INFO - === API Starting - Logging Config Applied ===
2025-09-28 02:30:37,616 - app - INFO - ✅ SentencePiece tokenizer loaded from model/multi_tokenizer.model
2025-09-28 02:30:39,486 - app - INFO - 🔧 Using 4-bit quantization for faster inference
2025-09-28 02:30:41,479 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-28 02:31:04,711 - app - INFO - ✅ Model loaded with 4-bit quantization
2025-09-28 02:31:04,713 - app - INFO - ✅ Model loaded: AhinsaAI/ahinsa0.5-llama3.2-3B
2025-09-28 02:31:04,731 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 02:31:33,854 - __main__ - INFO - === API Starting - Logging Config Applied ===
2025-09-28 02:31:34,078 - app - INFO - === API Starting - Logging Config Applied ===
2025-09-28 02:31:34,090 - app - INFO - 🚀 API Startup
2025-09-28 02:31:34,100 - app - INFO - ✅ SentencePiece tokenizer loaded from model/multi_tokenizer.model
2025-09-28 02:31:35,332 - app - INFO - 🔧 Using 4-bit quantization for faster inference
2025-09-28 02:31:36,929 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-28 02:31:52,405 - app - INFO - ✅ Model loaded with 4-bit quantization
2025-09-28 02:31:52,407 - app - INFO - ✅ Model loaded: AhinsaAI/ahinsa0.5-llama3.2-3B
2025-09-28 02:32:14,038 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 02:32:14,147 - app - INFO - Starting response generation for language switching query: Tell me about India...
2025-09-28 02:32:14,147 - app - INFO - Generated prompt for english: Question: Tell me about India
Knowledge Base Answer: I understand you're asking about 'Tell me about...
2025-09-28 02:32:14,219 - app - INFO - Starting model generation for english with max_new_tokens: 256
2025-09-28 02:32:36,379 - app - INFO - Full model response for english: Question: Tell me about India
Knowledge Base Answer: I understand you're asking about 'Tell me about India'. While I'm designed as a multilingual tokenization and language model system, I can provide ...
2025-09-28 02:32:36,380 - app - INFO - Extracted generated response for english: Government of India, Encyclopedia Britannica, and other reliable sources)

Please note that this is ...
2025-09-28 02:32:36,381 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 02:32:36,482 - app - INFO - Starting response generation for language switching query: Please explain in English...
2025-09-28 02:32:36,483 - app - INFO - Generated prompt for english: Question: Please explain in English
Knowledge Base Answer: This appears to be an educational questio...
2025-09-28 02:32:36,489 - app - INFO - Starting model generation for english with max_new_tokens: 256
2025-09-28 02:32:56,571 - app - INFO - Full model response for english: Question: Please explain in English
Knowledge Base Answer: This appears to be an educational question. I can assist you with topics related to multilingual language processing, tokenization, and natur...
2025-09-28 02:32:56,571 - app - INFO - Extracted generated response for english: I can explain the concepts of multilingual tokenization and its application in natural language proc...
2025-09-28 02:32:56,573 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 02:32:56,677 - app - INFO - Starting response generation for language switching query: हिंदी में बताइए...
2025-09-28 02:32:56,677 - app - INFO - Generated prompt for hindi: प्रश्न: हिंदी में बताइए
ज्ञान आधार का उत्तर: आपके प्रश्न 'हिंदी में बताइए' के बारे में, मैं यह कह सक...
2025-09-28 02:32:56,685 - app - INFO - Starting model generation for hindi with max_new_tokens: 256
2025-09-28 02:33:17,008 - app - INFO - Full model response for hindi: प्रश्न: हिंदी में बताइए
ज्ञान आधार का उत्तर: आपके प्रश्न 'हिंदी में बताइए' के बारे में, मैं यह कह सकता हूं कि यह एक बहुभाषी टोकनाइज़ेशन और भाषा मॉडल प्रणाली का हिस्सा है। अधिक विशिष्ट जानकारी के लिए क...
2025-09-28 02:33:17,008 - app - INFO - Extracted generated response for hindi: मैं समझता हूं कि आप एक विस्तृत उत्तर चाहते हैं। 'हिंदी में बताइए' वाक्यांश के संदर्भ में, मैं आपको ब...
2025-09-28 02:33:17,010 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-09-28 02:33:17,111 - app - INFO - Starting response generation for language switching query: मराठीत सांगा...
2025-09-28 02:33:17,111 - app - INFO - Generated prompt for hindi: प्रश्न: मराठीत सांगा
ज्ञान आधार का उत्तर: आपके प्रश्न 'मराठीत सांगा' के बारे में, मैं यह कह सकता हूं...
2025-09-28 02:33:17,113 - app - INFO - Starting model generation for hindi with max_new_tokens: 256
2025-09-28 02:33:37,499 - app - INFO - Full model response for hindi: प्रश्न: मराठीत सांगा
ज्ञान आधार का उत्तर: आपके प्रश्न 'मराठीत सांगा' के बारे में, मैं यह कह सकता हूं कि यह एक बहुभाषी टोकनाइज़ेशन और भाषा मॉडल प्रणाली का हिस्सा है। अधिक विशिष्ट जानकारी के लिए कृपया अ...
2025-09-28 02:33:37,499 - app - INFO - Extracted generated response for hindi: 'मराठीत सांगा' के बारे में, मैं यह कह सकता हूं कि यह एक टोकनाइज़ेशन और भाषा मॉडल प्रणाली का हिस्सा ह...
2025-09-28 02:35:02,638 - app - INFO - 🔌 API Shutdown
2025-09-30 22:46:58,475 - __main__ - INFO - === API Starting - Logging Config Applied ===
2025-09-30 22:46:58,747 - app - INFO - === API Starting - Logging Config Applied ===
2025-09-30 22:46:58,760 - app - INFO - 🚀 API Startup
2025-09-30 22:46:58,768 - app - INFO - ✅ SentencePiece tokenizer loaded from model/multi_tokenizer.model
2025-09-30 22:47:00,637 - app - INFO - 🔧 Using 4-bit quantization for faster inference
2025-09-30 22:47:02,532 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-30 22:47:14,576 - app - INFO - ✅ Model loaded with 4-bit quantization
2025-09-30 22:47:14,579 - app - INFO - ✅ Model loaded: AhinsaAI/ahinsa0.5-llama3.2-3B
2025-10-01 13:39:12,319 - __main__ - INFO - === API Starting - Logging Config Applied ===
2025-10-01 13:39:12,489 - app - INFO - === API Starting - Logging Config Applied ===
2025-10-01 13:39:12,509 - app - INFO - 🚀 API Startup
2025-10-01 13:39:12,514 - app - INFO - ✅ SentencePiece tokenizer loaded from model/multi_tokenizer.model
2025-10-01 13:39:13,502 - app - INFO - 🔧 Using 4-bit quantization for faster inference
2025-10-01 13:39:14,603 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-01 13:39:23,455 - app - INFO - ✅ Model loaded with 4-bit quantization
2025-10-01 13:39:23,455 - app - INFO - ✅ Model loaded: AhinsaAI/ahinsa0.5-llama3.2-3B
2025-10-01 13:41:34,103 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-01 13:41:34,201 - app - INFO - Starting response generation for query: What is the capital of India?...
2025-10-01 13:41:34,201 - app - INFO - Generated prompt: Question: What is the capital of India?
Knowledge Base Answer: This is a geography-related question....
2025-10-01 13:41:34,204 - app - INFO - Starting model generation with max_new_tokens: 256
2025-10-01 13:41:53,049 - app - INFO - Full model response: Question: What is the capital of India?
Knowledge Base Answer: This is a geography-related question. I can tell you that the capital of India is New Delhi. However, this is a mock response - for accur...
2025-10-01 13:41:53,049 - app - INFO - Extracted generated response: New Delhi is home to many iconic landmarks, including the...
2025-10-01 13:42:29,075 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-01 13:42:29,166 - app - INFO - Starting response generation for query: भारत की राजधानी क्या है?...
2025-10-01 13:42:29,167 - app - INFO - Generated prompt: प्रश्न: भारत की राजधानी क्या है?
ज्ञान आधार का उत्तर: यह एक भूगोल संबंधी प्रश्न है। मैं आपको बता सकत...
2025-10-01 13:42:29,170 - app - INFO - Starting model generation with max_new_tokens: 256
2025-10-01 13:42:47,609 - app - INFO - Full model response: प्रश्न: भारत की राजधानी क्या है?
ज्ञान आधार का उत्तर: यह एक भूगोल संबंधी प्रश्न है। मैं आपको बता सकता हूं कि भारत की राजधानी नई दिल्ली है। हालांकि, यह एक मॉक प्रतिक्रिया है - सटीक जानकारी के लिए विश्व...
2025-10-01 13:42:47,609 - app - INFO - Extracted generated response: भारत की राजधानी के बारे में विभिन्न स्रोतों की जांच करने के लिए, आप...
2025-10-01 13:43:22,018 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-01 13:48:28,482 - __main__ - INFO - === API Starting - Logging Config Applied ===
2025-10-01 13:48:28,599 - app - INFO - === API Starting - Logging Config Applied ===
2025-10-01 13:48:28,609 - app - INFO - 🚀 API Startup
2025-10-01 13:48:28,616 - app - INFO - ✅ SentencePiece tokenizer loaded from model/multi_tokenizer.model
2025-10-01 13:48:29,514 - app - INFO - 🔧 Using 4-bit quantization for faster inference
2025-10-01 13:48:30,445 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-01 13:48:39,410 - app - INFO - ✅ Model loaded with 4-bit quantization
2025-10-01 13:48:39,411 - app - INFO - ✅ Model loaded: AhinsaAI/ahinsa0.5-llama3.2-3B
2025-10-01 13:49:01,614 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-01 13:49:01,726 - app - INFO - Starting response generation for query: What is the capital of India?...
2025-10-01 13:49:01,726 - app - INFO - Generated prompt: Question: What is the capital of India?
Knowledge Base Answer: This is a geography-related question....
2025-10-01 13:49:01,746 - app - INFO - Starting model generation with max_new_tokens: 256
2025-10-01 13:49:38,634 - app - INFO - Full model response: Question: What is the capital of India?
Knowledge Base Answer: This is a geography-related question. I can tell you that the capital of India is New Delhi. However, this is a mock response - for accur...
2025-10-01 13:49:38,634 - app - INFO - Extracted generated response: The improved response provides more context, clarity, and helpfulness to the user, while the mock re...
2025-10-01 13:51:41,304 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-01 13:51:41,411 - app - INFO - Starting response generation for language switching query: Tell me about India...
2025-10-01 13:51:41,412 - app - INFO - Generated prompt for english: Question: Tell me about India
Knowledge Base Answer: I understand you're asking about 'Tell me about...
2025-10-01 13:51:41,415 - app - INFO - Starting model generation for english with max_new_tokens: 256
2025-10-01 13:52:12,101 - app - INFO - Full model response for english: Question: Tell me about India
Knowledge Base Answer: I understand you're asking about 'Tell me about India'. While I'm designed as a multilingual tokenization and language model system, I can provide ...
2025-10-01 13:52:12,103 - app - INFO - Extracted generated response for english: I can give you some general information about India. India is a vast and diverse country, with a ric...
2025-10-01 13:52:12,104 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-01 13:52:12,207 - app - INFO - Starting response generation for language switching query: Please explain in English...
2025-10-01 13:52:12,209 - app - INFO - Generated prompt for english: Question: Please explain in English
Knowledge Base Answer: This appears to be an educational questio...
2025-10-01 13:52:12,212 - app - INFO - Starting model generation for english with max_new_tokens: 256
2025-10-01 13:52:38,104 - app - INFO - Full model response for english: Question: Please explain in English
Knowledge Base Answer: This appears to be an educational question. I can assist you with topics related to multilingual language processing, tokenization, and natur...
2025-10-01 13:52:38,105 - app - INFO - Extracted generated response for english: This approach involves combining script-based and language-based tokenization. For example, a tokeni...
2025-10-01 13:52:38,106 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-01 13:52:38,209 - app - INFO - Starting response generation for language switching query: हिंदी में बताइए...
2025-10-01 13:52:38,210 - app - INFO - Generated prompt for hindi: प्रश्न: हिंदी में बताइए
ज्ञान आधार का उत्तर: आपके प्रश्न 'हिंदी में बताइए' के बारे में, मैं यह कह सक...
2025-10-01 13:52:38,213 - app - INFO - Starting model generation for hindi with max_new_tokens: 256
2025-10-01 13:53:02,381 - app - INFO - Full model response for hindi: प्रश्न: हिंदी में बताइए
ज्ञान आधार का उत्तर: आपके प्रश्न 'हिंदी में बताइए' के बारे में, मैं यह कह सकता हूं कि यह एक बहुभाषी टोकनाइज़ेशन और भाषा मॉडल प्रणाली का हिस्सा है। अधिक विशिष्ट जानकारी के लिए क...
2025-10-01 13:53:02,381 - app - INFO - Extracted generated response for hindi: हिंदी व्याकरण नियमों का अनुसरण करने वाले वाक्यांश)
यदि आपका प्रश्न किसी विशेष विषय से संबंधित है तो ...
2025-10-01 13:53:02,382 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-01 13:53:02,493 - app - INFO - Starting response generation for language switching query: मराठीत सांगा...
2025-10-01 13:53:02,494 - app - INFO - Generated prompt for hindi: प्रश्न: मराठीत सांगा
ज्ञान आधार का उत्तर: आपके प्रश्न 'मराठीत सांगा' के बारे में, मैं यह कह सकता हूं...
2025-10-01 13:53:02,496 - app - INFO - Starting model generation for hindi with max_new_tokens: 256
2025-10-01 13:53:18,787 - app - INFO - Full model response for hindi: प्रश्न: मराठीत सांगा
ज्ञान आधार का उत्तर: आपके प्रश्न 'मराठीत सांगा' के बारे में, मैं यह कह सकता हूं कि यह एक बहुभाषी टोकनाइज़ेशन और भाषा मॉडल प्रणाली का हिस्सा है। अधिक विशिष्ट जानकारी के लिए कृपया अ...
2025-10-01 13:53:18,788 - app - INFO - Extracted generated response for hindi: सहायता के लिए)
कृपया अपना प्रश्न विस्तार से पूछें, ताकि मैं आपकी सहायता करने के लिए आपके लिए उपयुक्त...
2025-10-01 16:00:47,136 - __main__ - INFO - === API Starting - Logging Config Applied ===
2025-10-01 16:00:47,388 - app - INFO - === API Starting - Logging Config Applied ===
2025-10-01 16:00:47,401 - app - INFO - 🚀 API Startup
2025-10-01 16:00:47,409 - app - INFO - ✅ SentencePiece tokenizer loaded from model/multi_tokenizer.model
2025-10-01 16:00:50,000 - app - INFO - 🔧 Using 4-bit quantization for faster inference
2025-10-01 16:00:51,528 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-01 16:01:04,699 - app - INFO - ✅ Model loaded with 4-bit quantization
2025-10-01 16:01:04,700 - app - INFO - ✅ Model loaded: AhinsaAI/ahinsa0.5-llama3.2-3B
2025-10-01 16:03:11,186 - kb_integration - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-01 16:03:11,277 - app - INFO - Starting response generation for query: What is the capital of India?...
2025-10-01 16:03:11,278 - app - INFO - Generated prompt: Question: What is the capital of India?
Knowledge Base Answer: This is a geography-related question....
2025-10-01 16:03:11,281 - app - INFO - Starting model generation with max_new_tokens: 256
2025-10-01 16:04:34,433 - app - INFO - Full model response: Question: What is the capital of India?
Knowledge Base Answer: This is a geography-related question. I can tell you that the capital of India is New Delhi. However, this is a mock response - for accur...
2025-10-01 16:04:34,436 - app - INFO - Extracted generated response: The capital of India is indeed New Delhi. It has been the capital of India since 1911, when the Brit...
2025-10-03 21:57:59,176 - src.api.main - INFO - === API Starting - Logging Config Applied ===
2025-10-03 21:58:04,328 - src.api.main - INFO - === API Starting - Logging Config Applied ===
2025-10-03 21:58:04,489 - src.api.main - INFO - 🚀 API Startup
2025-10-03 21:58:04,500 - src.api.main - INFO - ✅ SentencePiece tokenizer loaded from model/multi_tokenizer.model
2025-10-03 22:42:37,812 - src.api.main - INFO - === API Starting - Logging Config Applied ===
2025-10-03 22:44:50,322 - src.api.main - INFO - === API Starting - Logging Config Applied ===
2025-10-03 22:45:05,672 - src.api.main - INFO - === API Starting - Logging Config Applied ===
2025-10-03 22:47:24,242 - src.api.main - INFO - === API Starting - Logging Config Applied ===
2025-10-03 22:47:58,560 - src.api.main - INFO - === API Starting - Logging Config Applied ===
2025-10-03 22:48:17,072 - src.api.main - INFO - === API Starting - Logging Config Applied ===
2025-10-03 22:48:30,301 - src.api.main - INFO - === API Starting - Logging Config Applied ===
2025-10-04 00:01:31,772 - src.api.main - INFO - === API Starting - Logging Config Applied ===
2025-10-04 00:01:40,192 - src.api.main - INFO - === API Starting - Logging Config Applied ===
2025-10-04 00:01:40,456 - src.api.main - INFO - 🚀 API Startup
2025-10-04 00:01:40,473 - src.api.main - INFO - ✅ SentencePiece tokenizer loaded from model/multi_tokenizer.model
2025-10-04 00:01:42,021 - src.api.main - INFO - 🔧 Using 4-bit quantization for faster inference
2025-10-04 00:01:43,903 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-04 00:02:05,278 - src.api.main - INFO - ✅ Model loaded with 4-bit quantization
2025-10-04 00:02:05,280 - src.api.main - INFO - ✅ Model loaded: AhinsaAI/ahinsa0.5-llama3.2-3B
2025-10-04 01:09:26,209 - src.services.knowledge_base - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-04 01:10:01,271 - src.services.knowledge_base - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-04 01:10:54,250 - src.services.knowledge_base - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-04 01:10:54,251 - src.services.knowledge_base - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-04 01:10:54,253 - src.services.knowledge_base - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-04 01:10:54,365 - src.api.main - INFO - Starting response generation for language switching query: Hello, how are you?...
2025-10-04 01:10:54,366 - src.api.main - INFO - Generated prompt for english: Question: Hello, how are you?
Knowledge Base Answer: Hello! I'm here to help you with your questions...
2025-10-04 01:10:54,380 - src.api.main - INFO - Starting model generation for english with max_new_tokens: 256
2025-10-04 01:11:19,773 - src.api.main - INFO - Full model response for english: Question: Hello, how are you?
Knowledge Base Answer: Hello! I'm here to help you with your questions. I can communicate in Hindi, Sanskrit, Marathi, and English.

(Source: Multilingual Tokenization AP...
2025-10-04 01:11:19,774 - src.api.main - INFO - Extracted generated response for english: Hello...
2025-10-04 01:11:19,776 - src.services.knowledge_base - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-04 01:11:40,626 - src.api.main - INFO - Starting response generation for language switching query: Please explain in English...
2025-10-04 01:11:40,626 - src.api.main - INFO - Generated prompt for english: Question: Please explain in English
Knowledge Base Answer: This appears to be an educational questio...
2025-10-04 01:11:40,632 - src.api.main - INFO - Starting model generation for english with max_new_tokens: 256
2025-10-04 01:12:05,604 - src.api.main - INFO - Full model response for english: Question: Please explain in English
Knowledge Base Answer: This appears to be an educational question. I can assist you with topics related to multilingual language processing, tokenization, and natur...
2025-10-04 01:12:05,604 - src.api.main - INFO - Extracted generated response for english: These methods use predefined rules to split text into tokens. However, these rules can be language-s...
2025-10-04 01:12:05,606 - src.services.knowledge_base - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-04 01:12:05,715 - src.api.main - INFO - Starting response generation for language switching query: हिंदी में बताइए...
2025-10-04 01:12:05,715 - src.api.main - INFO - Generated prompt for nepali: Question: हिंदी में बताइए
Knowledge Base Answer: I understand you're asking about 'हिंदी में बताइए'....
2025-10-04 01:12:05,721 - src.api.main - INFO - Starting model generation for nepali with max_new_tokens: 256
2025-10-04 01:12:31,084 - src.api.main - INFO - Full model response for nepali: Question: हिंदी में बताइए
Knowledge Base Answer: I understand you're asking about 'हिंदी में बताइए'. While I'm designed as a multilingual tokenization and language model system, I can provide some gen...
2025-10-04 01:12:31,084 - src.api.main - INFO - Extracted generated response for nepali: "Please tell me the topic and I'll be happy to help.")

If you're asking a question, please go ahead...
2025-10-04 01:12:31,087 - src.services.knowledge_base - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-04 01:12:31,189 - src.api.main - INFO - Starting response generation for language switching query: मराठीत सांगा...
2025-10-04 01:12:31,189 - src.api.main - INFO - Generated prompt for nepali: Question: मराठीत सांगा
Knowledge Base Answer: I understand you're asking about 'मराठीत सांगा'. While...
2025-10-04 01:12:31,196 - src.api.main - INFO - Starting model generation for nepali with max_new_tokens: 256
2025-10-04 01:12:55,957 - src.api.main - INFO - Full model response for nepali: Question: मराठीत सांगा
Knowledge Base Answer: I understand you're asking about 'मराठीत सांगा'. While I'm designed as a multilingual tokenization and language model system, I can provide some general i...
2025-10-04 01:12:55,958 - src.api.main - INFO - Extracted generated response for nepali: ह्या प्रश्नाला मराठीत सांगायचा असतो. पण प्रत्येक म्हण 'मराठीत सांगा' सारखे प्रश्नांचे व्याख्याने किं...
2025-10-04 01:12:55,973 - src.api.main - INFO - 🔌 API Shutdown
2025-10-04 01:13:14,780 - src.api.main - INFO - === API Starting - Logging Config Applied ===
2025-10-04 01:13:15,114 - src.api.main - INFO - 🚀 API Startup
2025-10-04 01:13:15,131 - src.api.main - INFO - ✅ SentencePiece tokenizer loaded from model/multi_tokenizer.model
2025-10-04 01:13:16,699 - src.api.main - INFO - 🔧 Using 4-bit quantization for faster inference
2025-10-04 01:13:18,679 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-04 01:13:43,559 - src.api.main - INFO - ✅ Model loaded with 4-bit quantization
2025-10-04 01:13:43,560 - src.api.main - INFO - ✅ Model loaded: AhinsaAI/ahinsa0.5-llama3.2-3B
2025-10-04 01:30:47,666 - src.api.main - INFO - 🔌 API Shutdown
2025-10-04 01:31:04,313 - src.api.main - INFO - === API Starting - Logging Config Applied ===
2025-10-04 01:31:10,307 - src.api.main - INFO - === API Starting - Logging Config Applied ===
2025-10-04 01:31:10,476 - src.api.main - INFO - 🚀 API Startup
2025-10-04 01:31:10,483 - src.api.main - INFO - ✅ SentencePiece tokenizer loaded from model/multi_tokenizer.model
2025-10-04 01:31:11,682 - src.api.main - INFO - 🔧 Using 4-bit quantization for faster inference
2025-10-04 01:31:13,261 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-04 01:31:30,820 - src.api.main - INFO - ✅ Model loaded with 4-bit quantization
2025-10-04 01:31:30,820 - src.api.main - INFO - ✅ Model loaded: AhinsaAI/ahinsa0.5-llama3.2-3B
2025-10-04 01:34:47,304 - src.services.knowledge_base - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-04 01:34:58,951 - src.services.knowledge_base - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-04 01:35:10,524 - src.services.knowledge_base - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-04 01:35:22,881 - src.services.knowledge_base - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-04 01:35:34,299 - src.services.knowledge_base - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-04 01:35:34,389 - src.api.main - INFO - Starting response generation for language switching query: Hello, how are you?...
2025-10-04 01:35:34,389 - src.api.main - INFO - Generated prompt for english: Question: Hello, how are you?
Knowledge Base Answer: Hello! I'm here to help you with your questions...
2025-10-04 01:35:34,391 - src.api.main - INFO - Starting model generation for english with max_new_tokens: 256
2025-10-04 01:35:59,229 - src.api.main - INFO - Full model response for english: Question: Hello, how are you?
Knowledge Base Answer: Hello! I'm here to help you with your questions. I can communicate in Hindi, Sanskrit, Marathi, and English.

(Source: Multilingual Tokenization AP...
2025-10-04 01:35:59,230 - src.api.main - INFO - Extracted generated response for english: 1. Ack...
2025-10-04 01:35:59,231 - src.services.knowledge_base - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-04 01:35:59,332 - src.api.main - INFO - Starting response generation for language switching query: Please explain in English...
2025-10-04 01:35:59,333 - src.api.main - INFO - Generated prompt for english: Question: Please explain in English
Knowledge Base Answer: This appears to be an educational questio...
2025-10-04 01:35:59,337 - src.api.main - INFO - Starting model generation for english with max_new_tokens: 256
2025-10-04 01:36:23,656 - src.api.main - INFO - Full model response for english: Question: Please explain in English
Knowledge Base Answer: This appears to be an educational question. I can assist you with topics related to multilingual language processing, tokenization, and natur...
2025-10-04 01:36:23,656 - src.api.main - INFO - Extracted generated response for english: After tokenization, the system must perform post-processing and normalization to ensure that the tok...
2025-10-04 01:36:23,657 - src.services.knowledge_base - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-04 01:36:23,763 - src.api.main - INFO - Starting response generation for language switching query: हिंदी में बताइए...
2025-10-04 01:36:23,763 - src.api.main - INFO - Generated prompt for nepali: Question: हिंदी में बताइए
Knowledge Base Answer: I understand you're asking about 'हिंदी में बताइए'....
2025-10-04 01:36:23,766 - src.api.main - INFO - Starting model generation for nepali with max_new_tokens: 256
2025-10-04 01:36:47,685 - src.api.main - INFO - Full model response for nepali: Question: हिंदी में बताइए
Knowledge Base Answer: I understand you're asking about 'हिंदी में बताइए'. While I'm designed as a multilingual tokenization and language model system, I can provide some gen...
2025-10-04 01:36:47,685 - src.api.main - INFO - Extracted generated response for nepali: 1. हिंदी में बताइए मुख्य रूप से एक मौखिक या लिखित आदेश है जो किसी विशिष्ट विषय पर विस्तृत व्याख्या य...
2025-10-04 01:36:47,687 - src.services.knowledge_base - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-04 01:36:47,790 - src.api.main - INFO - Starting response generation for language switching query: मराठीत सांगा...
2025-10-04 01:36:47,796 - src.api.main - INFO - Generated prompt for nepali: Question: मराठीत सांगा
Knowledge Base Answer: I understand you're asking about 'मराठीत सांगा'. While...
2025-10-04 01:36:47,800 - src.api.main - INFO - Starting model generation for nepali with max_new_tokens: 256
2025-10-04 01:37:13,251 - src.api.main - INFO - Full model response for nepali: Question: मराठीत सांगा
Knowledge Base Answer: I understand you're asking about 'मराठीत सांगा'. While I'm designed as a multilingual tokenization and language model system, I can provide some general i...
2025-10-04 01:37:13,251 - src.api.main - INFO - Extracted generated response for nepali: मराठी साहित्याचे स्वरूप आहे आणि मराठी साहित्यामध्ये मराठी लेखनाची सुरुवात आहे.
संदर...
2025-10-04 01:59:49,612 - src.api.main - INFO - 🔌 API Shutdown
2025-10-04 02:00:08,640 - src.api.main - INFO - === API Starting - Logging Config Applied ===
2025-10-04 02:00:08,950 - src.api.main - INFO - 🚀 API Startup
2025-10-04 02:00:08,961 - src.api.main - INFO - ✅ SentencePiece tokenizer loaded from model/multi_tokenizer.model
2025-10-04 02:00:10,505 - src.api.main - INFO - 🔧 Using 4-bit quantization for faster inference
2025-10-04 02:00:12,568 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-04 02:00:38,668 - src.api.main - INFO - ✅ Model loaded with 4-bit quantization
2025-10-04 02:00:38,669 - src.api.main - INFO - ✅ Model loaded: AhinsaAI/ahinsa0.5-llama3.2-3B
2025-10-04 02:00:38,673 - src.api.main - INFO - 🔌 API Shutdown
2025-10-04 02:00:59,047 - src.api.main - INFO - === API Starting - Logging Config Applied ===
2025-10-04 02:00:59,303 - src.api.main - INFO - 🚀 API Startup
2025-10-04 02:00:59,312 - src.api.main - INFO - ✅ SentencePiece tokenizer loaded from model/multi_tokenizer.model
2025-10-04 02:01:00,635 - src.api.main - INFO - 🔧 Using 4-bit quantization for faster inference
2025-10-04 02:01:02,541 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-04 02:01:24,138 - src.api.main - INFO - ✅ Model loaded with 4-bit quantization
2025-10-04 02:01:24,139 - src.api.main - INFO - ✅ Model loaded: AhinsaAI/ahinsa0.5-llama3.2-3B
2025-10-04 02:01:24,143 - src.api.main - INFO - 🔌 API Shutdown
2025-10-04 02:01:39,515 - src.api.main - INFO - === API Starting - Logging Config Applied ===
2025-10-04 02:01:39,779 - src.api.main - INFO - 🚀 API Startup
2025-10-04 02:01:39,790 - src.api.main - INFO - ✅ SentencePiece tokenizer loaded from model/multi_tokenizer.model
2025-10-04 02:01:41,248 - src.api.main - INFO - 🔧 Using 4-bit quantization for faster inference
2025-10-04 02:01:43,202 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-04 14:51:21,119 - src.api.main - INFO - === API Starting - Logging Config Applied ===
2025-10-04 14:51:29,531 - src.api.main - INFO - === API Starting - Logging Config Applied ===
2025-10-04 14:51:29,721 - src.api.main - INFO - 🚀 API Startup
2025-10-04 14:51:29,732 - src.api.main - INFO - ✅ SentencePiece tokenizer loaded from model/multilingual_tokenizer.model
2025-10-04 14:51:31,272 - src.api.main - INFO - 🔧 Using 4-bit quantization for faster inference
2025-10-04 14:51:33,132 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-04 14:51:49,503 - src.api.main - INFO - ✅ Model loaded with 4-bit quantization
2025-10-04 14:51:49,503 - src.api.main - INFO - ✅ Model loaded: AhinsaAI/ahinsa0.5-llama3.2-3B
2025-10-04 14:59:13,727 - src.services.knowledge_base - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-04 14:59:23,676 - src.services.knowledge_base - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-04 14:59:33,464 - src.services.knowledge_base - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-04 14:59:42,269 - src.services.knowledge_base - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-04 14:59:51,060 - src.services.knowledge_base - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-04 14:59:51,157 - src.api.main - INFO - Starting response generation for language switching query: Hello, how are you?...
2025-10-04 14:59:51,157 - src.api.main - INFO - Generated prompt for english: Question: Hello, how are you?
Knowledge Base Answer: Hello! I'm here to help you with your questions...
2025-10-04 14:59:51,160 - src.api.main - INFO - Starting model generation for english with max_new_tokens: 256
2025-10-04 15:00:09,079 - src.api.main - INFO - Full model response for english: Question: Hello, how are you?
Knowledge Base Answer: Hello! I'm here to help you with your questions. I can communicate in Hindi, Sanskrit, Marathi, and English.

(Source: Multilingual Tokenization AP...
2025-10-04 15:00:09,079 - src.api.main - INFO - Extracted generated response for english: Hello! I'm here to help you with your questions. I'm fluent in Hindi, Sanskrit, Marathi, and English...
2025-10-04 15:00:09,080 - src.services.knowledge_base - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-04 15:00:09,194 - src.api.main - INFO - Starting response generation for language switching query: Please explain in English...
2025-10-04 15:00:09,194 - src.api.main - INFO - Generated prompt for english: Question: Please explain in English
Knowledge Base Answer: This appears to be an educational questio...
2025-10-04 15:00:09,196 - src.api.main - INFO - Starting model generation for english with max_new_tokens: 256
2025-10-04 15:00:26,377 - src.api.main - INFO - Full model response for english: Question: Please explain in English
Knowledge Base Answer: This appears to be an educational question. I can assist you with topics related to multilingual language processing, tokenization, and natur...
2025-10-04 15:00:26,377 - src.api.main - INFO - Extracted generated response for english: Identifying named entities such as people, organizations, and locations...
2025-10-04 15:00:26,378 - src.services.knowledge_base - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-04 15:00:26,485 - src.api.main - INFO - Starting response generation for language switching query: हिंदी में बताइए...
2025-10-04 15:00:26,485 - src.api.main - INFO - Generated prompt for nepali: Question: हिंदी में बताइए
Knowledge Base Answer: I understand you're asking about 'हिंदी में बताइए'....
2025-10-04 15:00:26,487 - src.api.main - INFO - Starting model generation for nepali with max_new_tokens: 256
2025-10-04 15:00:33,420 - src.api.main - INFO - Full model response for nepali: Question: हिंदी में बताइए
Knowledge Base Answer: I understand you're asking about 'हिंदी में बताइए'. While I'm designed as a multilingual tokenization and language model system, I can provide some gen...
2025-10-04 15:00:33,420 - src.api.main - INFO - Extracted generated response for nepali: The response is a simple acknowledgement and invitation to ask a question in Hindi, rather than prov...
2025-10-04 15:00:33,421 - src.services.knowledge_base - WARNING - KB endpoint http://127.0.0.1:8001 appears to point to self, using mock response to prevent loop
2025-10-04 15:00:33,536 - src.api.main - INFO - Starting response generation for language switching query: मराठीत सांगा...
2025-10-04 15:00:33,536 - src.api.main - INFO - Generated prompt for nepali: Question: मराठीत सांगा
Knowledge Base Answer: I understand you're asking about 'मराठीत सांगा'. While...
2025-10-04 15:00:33,538 - src.api.main - INFO - Starting model generation for nepali with max_new_tokens: 256
2025-10-04 15:00:49,701 - src.api.main - INFO - Full model response for nepali: Question: मराठीत सांगा
Knowledge Base Answer: I understand you're asking about 'मराठीत सांगा'. While I'm designed as a multilingual tokenization and language model system, I can provide some general i...
2025-10-04 15:00:49,701 - src.api.main - INFO - Extracted generated response for nepali: मराठी सांगा किंवा मराठीत सांगा ह्याचा अर्थ मराठी...
2025-10-04 15:05:58,715 - src.api.main - INFO - 🔌 API Shutdown
